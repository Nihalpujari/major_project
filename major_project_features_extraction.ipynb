{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies (if not already installed)\n",
        "!pip install librosa scikit-learn joblib\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "# 1️⃣ Feature Extraction\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20).mean(axis=1)\n",
        "        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
        "        f0, _, _ = librosa.pyin(y, fmin=50, fmax=300, sr=sr)\n",
        "        median_pitch = np.nanmedian(f0) if f0 is not None else 0\n",
        "        zcr = librosa.feature.zero_crossing_rate(y=y).mean()\n",
        "        rms = librosa.feature.rms(y=y).mean()\n",
        "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()\n",
        "        chroma = librosa.feature.chroma_stft(y=y, sr=sr).mean()\n",
        "\n",
        "        return np.hstack([mfcc, spectral_centroid, median_pitch, zcr, rms, spectral_bandwidth, chroma])\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting features from {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# 2️⃣ Load Dataset\n",
        "def load_dataset(dataset_path):\n",
        "    dataset = []\n",
        "    speakers = os.listdir(dataset_path)\n",
        "\n",
        "    for speaker in speakers:\n",
        "        speaker_path = os.path.join(dataset_path, speaker)\n",
        "        if os.path.isdir(speaker_path):\n",
        "            for audio_file in os.listdir(speaker_path):\n",
        "                file_path = os.path.join(speaker_path, audio_file)\n",
        "                if file_path.endswith(\".wav\"):\n",
        "                    features = extract_features(file_path)\n",
        "                    if features is not None:\n",
        "                        dataset.append({\"features\": features, \"label\": speaker})\n",
        "\n",
        "    if len(dataset) < 1:\n",
        "        raise ValueError(\"No valid audio data found in the dataset path.\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# 3️⃣ Train Model\n",
        "def train_model(dataset):\n",
        "    X = [data[\"features\"] for data in dataset]\n",
        "    y = [data[\"label\"] for data in dataset]\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(y)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'max_depth': [3, 5]\n",
        "    }\n",
        "\n",
        "    gb = GradientBoostingClassifier(random_state=42)\n",
        "    clf = GridSearchCV(gb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    best_model = clf.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    print(\"\\n✅ Best Parameters:\", clf.best_params_)\n",
        "    print(\"\\n✅ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "    return best_model, scaler, label_encoder\n",
        "\n",
        "\n",
        "# 4️⃣ Run Training\n",
        "dataset_path = \"/content/voices\"  # ⚠️ Upload your dataset folder here in Colab\n",
        "dataset = load_dataset(dataset_path)\n",
        "model, scaler, label_encoder = train_model(dataset)\n",
        "\n",
        "# 5️⃣ Save Model Files\n",
        "joblib.dump(model, '/content/speaker_model.pkl')\n",
        "joblib.dump(scaler, '/content/scaler.pkl')\n",
        "joblib.dump(label_encoder, '/content/label_encoder.pkl')\n",
        "\n",
        "print(\"\\n✅ Model and files saved successfully!\")\n",
        "\n",
        "# 6️⃣ Download Model Files\n",
        "from google.colab import files\n",
        "files.download('/content/speaker_model.pkl')\n",
        "files.download('/content/scaler.pkl')\n",
        "files.download('/content/label_encoder.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "KLYuQBDurKwK",
        "outputId": "ef9a43a1-fb7f-4086-be80-ce5e9e8e4b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "\n",
            "✅ Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
            "\n",
            "✅ Confusion Matrix:\n",
            " [[2 0 0]\n",
            " [0 2 0]\n",
            " [0 0 2]]\n",
            "\n",
            "✅ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Aateet       1.00      1.00      1.00         2\n",
            "       mamta       1.00      1.00      1.00         2\n",
            "       vibha       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         6\n",
            "   macro avg       1.00      1.00      1.00         6\n",
            "weighted avg       1.00      1.00      1.00         6\n",
            "\n",
            "\n",
            "✅ Model and files saved successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_48a7085d-13e5-4eaf-bcd3-18ce13620529\", \"speaker_model.pkl\", 209373)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b2b03f38-f768-4e6c-93c6-27117de5f61a\", \"scaler.pkl\", 1239)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0dcf8d9f-64d0-4fbf-9baf-7bec3587df59\", \"label_encoder.pkl\", 399)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}